import locale
import os
from peft import PeftModel
import torch

current_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
lora_dir = os.path.join(current_dir, "model", "LORA")

# è·å– lora_path ä¸­çš„æ‰€æœ‰æ–‡ä»¶å¤¹åˆ—è¡¨
lora_list = [f for f in os.listdir(lora_dir) if os.path.isdir(os.path.join(lora_dir, f))]

def merge_lora_weights(model, lora_path):
    # åŠ è½½ LoRA æƒé‡
    model = PeftModel.from_pretrained(model, lora_path)
    return model

class load_llm_lora:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "is_enable": ("BOOLEAN", {"default": True}),
                "model": ("CUSTOM", {}),
                "lora_path": ("STRING", {"default": ""}),
            }
        }

    RETURN_TYPES = ("CUSTOM",)
    RETURN_NAMES = ("model",)

    FUNCTION = "apply_lora"  # å°† FUNCTION æŒ‡å‘å®é™…çš„æ–¹æ³•å

    OUTPUT_NODE = True

    CATEGORY = "å¤§æ¨¡å‹æ´¾å¯¹ï¼ˆllm_partyï¼‰/æ¨¡å‹åŠ è½½å™¨ï¼ˆmodel loaderï¼‰"

    def apply_lora(self, model, lora_path, is_enable=True):
        # åˆå¹¶ LoRA æƒé‡
        model = merge_lora_weights(model, lora_path)
        
        if is_enable:
            model.enable_adapter_layers()  # å¯ç”¨ LoRA å±‚
        else:
            model.disable_adapter_layers()  # ç¦ç”¨ LoRA å±‚
        
        return (model,)

        
class easy_load_llm_lora:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "is_enable": ("BOOLEAN", {"default":True}),
                "model": ("CUSTOM", {}),
                "lora_path": (lora_list, {"default": ""}),
            }
        }

    RETURN_TYPES = ("CUSTOM",)
    RETURN_NAMES = ("model",)

    FUNCTION = "sleep"

    OUTPUT_NODE = True

    CATEGORY = "å¤§æ¨¡å‹æ´¾å¯¹ï¼ˆllm_partyï¼‰/æ¨¡å‹åŠ è½½å™¨ï¼ˆmodel loaderï¼‰"

    def sleep(self,model,lora_path,is_enable=True):
        lora_path=os.path.join(lora_dir,lora_path)
        model=merge_lora_weights(model, lora_path)
        if is_enable:
            model.enable_adapter_layers()  # å¯ç”¨ LoRA å±‚
        else:
            model.disable_adapter_layers()  # ç¦ç”¨ LoRA å±‚

        return (model,)
    
NODE_CLASS_MAPPINGS = {"load_llm_lora": load_llm_lora, "easy_load_llm_lora": easy_load_llm_lora}
# è·å–ç³»ç»Ÿè¯­è¨€
lang = locale.getlocale()[0]
if 'Chinese' in lang:
   lang = 'zh_CN'
else:
   lang = 'en_US'
import os
import sys
current_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
config_path = os.path.join(current_dir, "config.ini")
import configparser
config = configparser.ConfigParser()
config.read(config_path)
try:
    language = config.get("API_KEYS", "language")
except:
    language = ""
if language == "zh_CN" or language=="en_US":
    lang=language
if lang == "zh_CN":
    NODE_DISPLAY_NAME_MAPPINGS = {"load_llm_lora": "ğŸ–¥ï¸åŠ è½½LLM LoRA", "easy_load_llm_lora": "ğŸ–¥ï¸ç®€æ˜“åŠ è½½LLM LoRA"}
else:
    NODE_DISPLAY_NAME_MAPPINGS = {"load_llm_lora": "ğŸ–¥ï¸Load LLM LoRA", "easy_load_llm_lora": "ğŸ–¥ï¸Easy Load LLM LoRA"}